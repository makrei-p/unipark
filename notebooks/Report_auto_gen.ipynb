{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "from unipark import Preprocessor\n",
    "from unipark import MetadataManipulator as MdManipulator\n",
    "from unipark import CodeBookPageManipulator as CbpManipulator\n",
    "from unipark import CodeBookParser\n",
    "\n",
    "from unipark.utils.frame import get_finishers, get_pausers, get_nonstarters\n",
    "from unipark.utils.plot import plot_worldmap, create_plot_from_truth_matrix, plot_wordcloud\n",
    "from unipark.utils.plots import single\n",
    "\n",
    "from functools import reduce\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the paths to the input CSV, codebook, and figures save directory from the paths.json file located in the same directory\n",
    "with open('configuration.json') as f:\n",
    "    configuration = json.load(f)\n",
    "input_csv = configuration['paths']['input_csv']\n",
    "codebook_path = configuration['paths']['codebook_path']\n",
    "figures_save_dir = configuration['paths']['figures_save_dir_autogen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_id_unifyer(x):\n",
    "    # Use this in case you performed the survey multiple times and concatenated the csvs --> page ids in multiple surveys are not identical and need to be normalized.\n",
    "    tl = {  # page map\n",
    "        110: 10,\n",
    "        120: 20,\n",
    "        130: 30,\n",
    "        210: 10,\n",
    "        220: 20,\n",
    "        230: 30,\n",
    "        310: 10,\n",
    "        230: 20,\n",
    "        330: 30,\n",
    "    }\n",
    "    if int(x) in tl:\n",
    "        x=str(tl[int(x)])\n",
    "    return x\n",
    "\n",
    "#cbp = CodeBookParser(codebook_path ,reassign_page_id=page_id_unifyer)\n",
    "cbp = CodeBookParser(codebook_path)\n",
    "\n",
    "codebook = cbp.get_codebook()\n",
    "page_name_by_id = {}\n",
    "for page in codebook['pages']:\n",
    "    page_name_by_id[page['id']] = page['title']\n",
    "\n",
    "def to_named_page(x):\n",
    "    return page_name_by_id[str(x)] if str(x) in page_name_by_id else str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pproc = Preprocessor(pd.read_csv(input_csv,sep=\";\"), to_named_page)\n",
    "pproc.drop_nonstarters()\n",
    "pproc.apply_manipulator(MdManipulator())\n",
    "for pagebook in cbp.get_codebook()['pages']:\n",
    "    pproc.apply_manipulator(CbpManipulator(pagebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# {}'.format(cbp.get_codebook()['title']))\n",
    "for page in pproc.pages:\n",
    "    if(len(pproc.question_ids_by_page[page]) > 0):\n",
    "        print('## {}'.format(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_markdown(question_id, headline_format='### {}', directory='./figs'):\n",
    "    ret = headline_format.format(pproc.get_question_title(question_id)) + '\\n'\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    path = os.path.join(directory, question_id)\n",
    "    \n",
    "    style = pproc.style_by_question_id[question_id]\n",
    "    columns = pproc.columns_by_question_id[question_id]\n",
    "    question = pproc.get_question_title(question_id)\n",
    "    my_data = pproc.get_data()\n",
    "    if 'single' == style:\n",
    "        ret += visualize_single(my_data, question_id=question_id, file_prefix=path)\n",
    "    elif 'multiple' == style:\n",
    "        ret += default_eval_multiple_question(my_data, columns=columns, file_prefix=path)\n",
    "    elif 'rank' == style:\n",
    "        print(f'{style} not supported yet!')\n",
    "    elif 'free' == style:\n",
    "        ret += default_eval_free_question(my_data, question_id=question_id, file_prefix=path)\n",
    "    elif 'freematrix' == style:\n",
    "        ret += default_eval_free_matrix(my_data, columns=columns, file_prefix=path)\n",
    "    elif 'matrix' == style:\n",
    "        ret += default_eval_matrix(my_data, columns=columns, file_prefix=path)\n",
    "    else:\n",
    "        assert False, 'Unknown stlye \"{}\"'.format(style)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_to_markdown(page, headline_format='## {}', directory='./figs'):\n",
    "    ret = headline_format.format(page) + '\\n'\n",
    "    question_ids = pproc.question_ids_by_page[page]\n",
    "    path = os.path.join(directory, page.replace(' ', '_').replace('?',''))\n",
    "    \n",
    "    if not question_ids:\n",
    "        ret = ret[:-1] + ': Empty\\n'\n",
    "        return ret\n",
    "    \n",
    "    for question_id in question_ids:\n",
    "        ret += question_to_markdown(question_id, directory=path)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_single_question(data: pd.DataFrame, question_id, file_prefix=None, show=False):\n",
    "    columns = pproc.columns_by_question_id[question_id]\n",
    "    vcs = data[columns[0]].value_counts()\n",
    "    count = reduce((lambda a,b:a+b), vcs.apply(lambda x: int(x) if x else 0), 0)\n",
    "    if count == 0:\n",
    "        return 'Nobody answered this question!'\n",
    "    ret = 'This question was answered by {} participants. The votes were distributed according to the following graphs:\\n'.format(count)\n",
    "    if len(vcs) <= 10:\n",
    "        # Pie chart\n",
    "        vcs.plot.pie()\n",
    "        if file_prefix is not None:\n",
    "            path = file_prefix + '_all_sorted_pie.png'\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "            plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        if show: _=plt.show()\n",
    "        else: plt.clf()\n",
    "        \n",
    "    # Bar chart\n",
    "    vcs.plot.bar()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_all_sorted_bar.png'\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "    \n",
    "    \n",
    "    # Finishers only\n",
    "    data = get_finishers(data)\n",
    "    vcs = data[columns[0]].value_counts()\n",
    "    count = reduce((lambda a,b:a+b), vcs.apply(lambda x: int(x) if x else 0))\n",
    "    ret += 'Looking at the votes of the {} finishers only, we receive the following distribution:\\n'.format(count)\n",
    "    \n",
    "    if len(vcs) <= 10:\n",
    "        # Pie chart\n",
    "        vcs.plot.pie()\n",
    "        if file_prefix is not None:\n",
    "            path = file_prefix + '_finishers_sorted_pie.png'\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "            plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        if show: _=plt.show()\n",
    "        else: plt.clf()\n",
    "        \n",
    "    # Bar chart\n",
    "    vcs.plot.bar()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_finishers_sorted_bar.png'\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "    \n",
    "    \n",
    "    # same but retain order\n",
    "    order = pproc.order_of_question_id[question_id]\n",
    "    vcs_ordered = get_ordered_value_counts(vcs, order)\n",
    "    \n",
    "    if len(vcs_ordered) <= 10:\n",
    "        # Pie chart\n",
    "        vcs_ordered.plot.pie()\n",
    "        if file_prefix is not None:\n",
    "            path = file_prefix + '_all_ordered_pie.png'\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "            plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        if show: _=plt.show()\n",
    "        else: plt.clf()\n",
    "        \n",
    "    # Bar chart\n",
    "    vcs_ordered.plot.bar()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_all_ordered_bar.png'\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "    \n",
    "    \n",
    "    # Finishers only\n",
    "    data = get_finishers(data)\n",
    "    vcs = data[columns[0]].value_counts()\n",
    "    vcs_ordered = get_ordered_value_counts(vcs, order)\n",
    "    count = reduce((lambda a,b:a+b), vcs.apply(lambda x: int(x) if x else 0))\n",
    "    ret += 'Looking at the votes of the {} finishers only, we receive the following distribution:\\n'.format(count)\n",
    "    \n",
    "    if len(vcs_ordered) <= 10:\n",
    "        # Pie chart\n",
    "        vcs_ordered.plot.pie()\n",
    "        if file_prefix is not None:\n",
    "            path = file_prefix + '_finishers_ordered_pie.png'\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "            plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        if show: _=plt.show()\n",
    "        else: plt.clf()\n",
    "        \n",
    "    # Bar chart\n",
    "    vcs_ordered.plot.bar()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_finishers_ordered_bar.png'\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "    \n",
    "    \n",
    "    # ToDo: Bar finisher over all\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a single choice question\n",
    "def visualize_single(data: pd.DataFrame, question_id, file_prefix=None, show=False):\n",
    "    columns = pproc.columns_by_question_id[question_id]\n",
    "    vcs = data[columns[0]].value_counts()\n",
    "    count = reduce((lambda a,b:a+b), vcs.apply(lambda x: int(x) if x else 0), 0)\n",
    "\n",
    "    # in case there are no answers, abort\n",
    "    if count == 0:\n",
    "        return 'Nobody answered this question!'\n",
    "    ret = 'This question was answered by {} participants.\\n'.format(count)\n",
    "\n",
    "    # for each configuration: construct the according visualization\n",
    "    for config in configuration['visualizations']['single']:\n",
    "        # order the values if configured so\n",
    "        if config['ordered']:\n",
    "            order = pproc.order_of_question_id[question_id]\n",
    "            vcs = get_ordered_value_counts(vcs, order)\n",
    "\n",
    "        ret += single.barchart(vcs, likert=config['likert'], file_prefix=file_prefix)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_value_counts(value_counts, order):\n",
    "    vcs_ordered = value_counts.copy()\n",
    "    for i in order:\n",
    "        if i not in vcs_ordered.index:\n",
    "            vcs_ordered[i]=0\n",
    "    forwards = dict(zip(order, np.arange(len(order))))\n",
    "    backwards = dict(zip(np.arange(len(order)), order))\n",
    "    vcs_ordered = vcs_ordered.rename(index=forwards).sort_index().rename(index=backwards)\n",
    "    return vcs_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_multiple_question(data, columns, file_prefix=None, show=False):\n",
    "    ret = ''\n",
    "    bool_columns = [x for x in columns if data[x].dtype==bool]\n",
    "    labels = [x[8:] for x in bool_columns]\n",
    "    create_plot_from_truth_matrix(data[bool_columns],names=labels, with_exclusives=True)\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_distribution_bar.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "    \n",
    "    #ticks = data[bool_columns].apply(np.count_nonzero, axis=1)\n",
    "    #sns.violinplot(x=ticks, cut=0)\n",
    "    #if file_prefix is not None:\n",
    "    #    path = file_prefix + '_vote-count_distribution_violin.png'\n",
    "    #    plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "    #    ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    #if show: _=plt.show()\n",
    "    #else: plt.clf()\n",
    "        \n",
    "    ticks = data[bool_columns].apply(np.count_nonzero, axis=1)\n",
    "    sns.histplot(x=ticks, discrete=True)\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_vote-count_distribution_hist.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()    \n",
    "        \n",
    "    non_bool_columns = [x for x in columns if x not in bool_columns]\n",
    "    for column in non_bool_columns:\n",
    "        path = file_prefix + '_'+column.replace(' ', '_').replace('?','') + '_wordcloud.png' if file_prefix else None\n",
    "        p = plot_wordcloud(data[column], save_file=path)\n",
    "        if path and p is not None:\n",
    "            ret += 'Of those ({}) who filled out \"{}\" the following wordcloud could be built:\\n'.format(\n",
    "                np.count_nonzero(data[column].apply(lambda x: x is not None)),\n",
    "                column)\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_matrix(data:pd.DataFrame, columns, file_prefix=None, show=False):\n",
    "    ret = ''\n",
    "    vcs = []\n",
    "    for col in columns[0]:\n",
    "        col_data = data[col]\n",
    "        col_vc = col_data.value_counts()\n",
    "        col_vc = col_vc.rename('count')\n",
    "        col_vc = col_vc.to_frame()\n",
    "        col_vc['answer'] = col_vc.index\n",
    "        col_vc['col'] = col\n",
    "        col_vc = col_vc.reset_index(drop=True)\n",
    "        vcs.append(col_vc)\n",
    "    counts = pd.concat(vcs)\n",
    "    \n",
    "    sns.barplot(data=counts, x='col', y='count', hue='answer')\n",
    "    plt.xticks(rotation=45, horizontalalignment='right')\n",
    "    plt.tight_layout()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_matrix_bar_q.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "        \n",
    "    sns.barplot(data=counts, hue='col', y='count', x='answer')\n",
    "    plt.xticks(rotation=45, horizontalalignment='right')\n",
    "    plt.tight_layout()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_matrix_bar_a.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_strs(a,b):\n",
    "    a = '' if a is None or (type(a)==float and np.isnan(a)) else str(a)\n",
    "    b = '' if b is None or (type(b)==float and np.isnan(b)) else str(b)\n",
    "    return a + ' ' + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_free_question(data, question_id, file_prefix=None, show=False):\n",
    "    series = data[pproc.columns_by_question_id[question_id][0]]\n",
    "    ret = 'A total of {} participants answered this question.\\n'.format(np.count_nonzero(series.apply(lambda x: x is not None)))\n",
    "    text = reduce(combine_strs, series)\n",
    "    \n",
    "    if text.strip():\n",
    "        # Generate word cloud\n",
    "        wordcloud = WordCloud(width = 3000, height = 1000, random_state=1, background_color='white', collocations=False, stopwords = STOPWORDS).generate(text)\n",
    "        \n",
    "        plt.figure(figsize=(40, 30))\n",
    "\n",
    "        # Display image\n",
    "        plt.imshow(wordcloud) \n",
    "        # No axis details\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "        if file_prefix:\n",
    "            ret += 'The answers result in the following wordcloud:\\n'\n",
    "            path = file_prefix + \"_wordcloud.png\"\n",
    "            plt.savefig(path, bbox_inches='tight')\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "\n",
    "        if not show:\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "    \n",
    "    return  ret\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_free_matrix(data:pd.DataFrame, columns, file_prefix=None, show=False):\n",
    "    ret = ''\n",
    "    for col in columns:\n",
    "        ret += '#' + str(col) + ':\\n'\n",
    "        col_data = data[col]\n",
    "        answers = [answer for answer in list(col_data.values) if answer is not None]\n",
    "        for answer in answers:\n",
    "            ret += '* ' + str(answer) + '\\n'\n",
    "        ret += '\\n'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = '# {}\\n'.format(cbp.get_codebook()['title'])\n",
    "print('# {}'.format(cbp.get_codebook()['title']))\n",
    "for page in [pproc.pages[2]]:\n",
    "    mpage = page_to_markdown(page, directory=figures_save_dir)\n",
    "    print (mpage)\n",
    "    report += mpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Report.md', 'w+') as file:\n",
    "    file.write(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
