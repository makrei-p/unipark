{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "from unipark import Preprocessor\n",
    "from unipark import MetadataManipulator as MdManipulator\n",
    "from unipark import CodeBookPageManipulator as CbpManipulator\n",
    "from unipark import CodeBookParser\n",
    "\n",
    "from unipark.utils.frame import get_finishers, get_pausers, get_nonstarters\n",
    "from unipark.utils.plot import plot_worldmap, create_plot_from_truth_matrix\n",
    "from unipark.utils.plots import single, free\n",
    "\n",
    "from functools import reduce\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the paths to the input CSV, codebook, and figures save directory from the paths.json file located in the same directory\n",
    "with open('configuration.json') as f:\n",
    "    configuration = json.load(f)\n",
    "input_csv = configuration['paths']['input_csv']\n",
    "codebook_path = configuration['paths']['codebook_path']\n",
    "figures_save_dir = configuration['paths']['figures_save_dir_autogen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_id_unifyer(x):\n",
    "    # Use this in case you performed the survey multiple times and concatenated the csvs --> page ids in multiple surveys are not identical and need to be normalized.\n",
    "    tl = {  # page map\n",
    "        110: 10,\n",
    "        120: 20,\n",
    "        130: 30,\n",
    "        210: 10,\n",
    "        220: 20,\n",
    "        230: 30,\n",
    "        310: 10,\n",
    "        230: 20,\n",
    "        330: 30,\n",
    "    }\n",
    "    if int(x) in tl:\n",
    "        x=str(tl[int(x)])\n",
    "    return x\n",
    "\n",
    "#cbp = CodeBookParser(codebook_path ,reassign_page_id=page_id_unifyer)\n",
    "cbp = CodeBookParser(codebook_path)\n",
    "\n",
    "codebook = cbp.get_codebook()\n",
    "page_name_by_id = {}\n",
    "for page in codebook['pages']:\n",
    "    page_name_by_id[page['id']] = page['title']\n",
    "\n",
    "def to_named_page(x):\n",
    "    return page_name_by_id[str(x)] if str(x) in page_name_by_id else str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pproc = Preprocessor(pd.read_csv(input_csv,sep=\";\"), to_named_page)\n",
    "pproc.drop_nonstarters()\n",
    "pproc.apply_manipulator(MdManipulator())\n",
    "for pagebook in cbp.get_codebook()['pages']:\n",
    "    pproc.apply_manipulator(CbpManipulator(pagebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Understanding Requirements Engineering Debt\n",
      "## Demographics\n",
      "## P1 Causes\n",
      "## P2 Value (1)\n",
      "## P2 Value (2)\n",
      "## P3 Symptoms (1)\n",
      "## P3 Symptoms (2)\n",
      "## P4 Intentionality\n",
      "## P5 Propagation\n",
      "## P6 Detecting\n",
      "## P7 Measuring\n",
      "## P8 Tracking\n",
      "## P9 Remediation\n"
     ]
    }
   ],
   "source": [
    "print('# {}'.format(cbp.get_codebook()['title']))\n",
    "for page in pproc.pages:\n",
    "    if(len(pproc.question_ids_by_page[page]) > 0):\n",
    "        print('## {}'.format(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_to_markdown(page, headline_format='## {}', directory='./figs'):\n",
    "    ret = headline_format.format(page) + '\\n'\n",
    "    question_ids = pproc.question_ids_by_page[page]\n",
    "    path = os.path.join(directory, page.replace(' ', '_').replace('?',''))\n",
    "    \n",
    "    if not question_ids:\n",
    "        ret = ret[:-1] + ': Empty\\n'\n",
    "        return ret\n",
    "    \n",
    "    for question_id in question_ids:\n",
    "        ret += question_to_markdown(question_id, directory=path)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_markdown(question_id, directory='./figs'):\n",
    "    ret = f'### {pproc.get_question_title(question_id)}\\n'\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    path = os.path.join(directory, question_id)\n",
    "    \n",
    "    style = pproc.style_by_question_id[question_id]\n",
    "    columns = pproc.columns_by_question_id[question_id]\n",
    "    my_data = pproc.get_data()\n",
    "    if 'single' == style:\n",
    "        ret += visualize_single(my_data, question_id=question_id, file_prefix=path)\n",
    "    elif 'multiple' == style:\n",
    "        # todo\n",
    "        ret += default_eval_multiple_question(my_data, columns=columns, file_prefix=path)\n",
    "    elif 'rank' == style:\n",
    "        print(f'{style} not supported yet!')\n",
    "    elif 'free' == style:\n",
    "        ret += visualize_free(my_data, question_id=question_id, file_prefix=path)\n",
    "    elif 'freematrix' == style:\n",
    "        ret += visualize_freematrix(my_data, columns=columns, file_prefix=path)\n",
    "    elif 'matrix' == style:\n",
    "        # todo\n",
    "        ret += default_eval_matrix(my_data, columns=columns, file_prefix=path)\n",
    "    else:\n",
    "        assert False, 'Unknown stlye \"{}\"'.format(style)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_value_counts(value_counts, order):\n",
    "    vcs_ordered = value_counts.copy()\n",
    "    for i in order:\n",
    "        if i not in vcs_ordered.index:\n",
    "            vcs_ordered[i]=0\n",
    "    forwards = dict(zip(order, np.arange(len(order))))\n",
    "    backwards = dict(zip(np.arange(len(order)), order))\n",
    "    vcs_ordered = vcs_ordered.rename(index=forwards).sort_index().rename(index=backwards)\n",
    "    return vcs_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a single choice question\n",
    "def visualize_single(data: pd.DataFrame, question_id, file_prefix=None, show=False):\n",
    "    columns = pproc.columns_by_question_id[question_id]\n",
    "    vcs = data[columns[0]].value_counts()\n",
    "    count = reduce((lambda a,b:a+b), vcs.apply(lambda x: int(x) if x else 0), 0)\n",
    "\n",
    "    # in case there are no answers, abort\n",
    "    if count == 0:\n",
    "        return 'Nobody answered this question!'\n",
    "    ret = 'This question was answered by {} participants.\\n'.format(count)\n",
    "\n",
    "    # for each configuration: construct the according visualization\n",
    "    for config in configuration['visualizations']['single']:\n",
    "        # only consider finishers if configured so\n",
    "        if config['finishers']:\n",
    "            data = get_finishers(data)\n",
    "            vcs = data[columns[0]].value_counts()\n",
    "\n",
    "        # order the values if configured so\n",
    "        if config['ordered']:\n",
    "            order = pproc.order_of_question_id[question_id]\n",
    "            vcs = get_ordered_value_counts(vcs, order)\n",
    "\n",
    "        # generate the appropriate chart type\n",
    "        if config['chart'] == 'bar':\n",
    "            ret += single.barchart(vcs, likert=config['likert'], file_prefix=file_prefix)\n",
    "        elif config['chart'] == 'pie':\n",
    "            ret += single.piechart(vcs, likert=config['likert'], file_prefix=file_prefix)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_multiple_question(data, columns, file_prefix=None, show=False):\n",
    "    ret = ''\n",
    "    bool_columns = [x for x in columns if data[x].dtype==bool]\n",
    "    labels = [x[8:] for x in bool_columns]\n",
    "    create_plot_from_truth_matrix(data[bool_columns],names=labels, with_exclusives=True)\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_distribution_bar.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "    \n",
    "    #ticks = data[bool_columns].apply(np.count_nonzero, axis=1)\n",
    "    #sns.violinplot(x=ticks, cut=0)\n",
    "    #if file_prefix is not None:\n",
    "    #    path = file_prefix + '_vote-count_distribution_violin.png'\n",
    "    #    plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "    #    ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    #if show: _=plt.show()\n",
    "    #else: plt.clf()\n",
    "        \n",
    "    ticks = data[bool_columns].apply(np.count_nonzero, axis=1)\n",
    "    sns.histplot(x=ticks, discrete=True)\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_vote-count_distribution_hist.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()    \n",
    "        \n",
    "    non_bool_columns = [x for x in columns if x not in bool_columns]\n",
    "    for column in non_bool_columns:\n",
    "        path = file_prefix + '_'+column.replace(' ', '_').replace('?','') + '_wordcloud.png' if file_prefix else None\n",
    "        p = free.wordcloud(data[column], file_prefix=path)\n",
    "        if path and p is not None:\n",
    "            ret += 'Of those ({}) who filled out \"{}\" the following wordcloud could be built:\\n'.format(\n",
    "                np.count_nonzero(data[column].apply(lambda x: x is not None)),\n",
    "                column)\n",
    "            ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_eval_matrix(data:pd.DataFrame, columns, file_prefix=None, show=False):\n",
    "    ret = ''\n",
    "    vcs = []\n",
    "    for col in columns[0]:\n",
    "        col_data = data[col]\n",
    "        col_vc = col_data.value_counts()\n",
    "        col_vc = col_vc.rename('count')\n",
    "        col_vc = col_vc.to_frame()\n",
    "        col_vc['answer'] = col_vc.index\n",
    "        col_vc['col'] = col\n",
    "        col_vc = col_vc.reset_index(drop=True)\n",
    "        vcs.append(col_vc)\n",
    "    counts = pd.concat(vcs)\n",
    "    \n",
    "    sns.barplot(data=counts, x='col', y='count', hue='answer')\n",
    "    plt.xticks(rotation=45, horizontalalignment='right')\n",
    "    plt.tight_layout()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_matrix_bar_q.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()\n",
    "        \n",
    "    sns.barplot(data=counts, hue='col', y='count', x='answer')\n",
    "    plt.xticks(rotation=45, horizontalalignment='right')\n",
    "    plt.tight_layout()\n",
    "    if file_prefix is not None:\n",
    "        path = file_prefix + '_matrix_bar_a.png'\n",
    "        plt.savefig(path, dpi=1200, bbox_inches='tight')\n",
    "        ret += '![alt text]({} \"Title\")\\n'.format(path)\n",
    "    if show: _=plt.show()\n",
    "    else: plt.clf()    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a free question (list of free, natural language text)\n",
    "def visualize_free(data, question_id, file_prefix=None, show=False):\n",
    "    series = data[pproc.columns_by_question_id[question_id][0]]\n",
    "    count = np.count_nonzero(series.apply(lambda x: x is not None))\n",
    "\n",
    "    # in case there are no answers, abort\n",
    "    if count == 0:\n",
    "        return 'Nobody answered this question!'\n",
    "    ret = 'This question was answered by {} participants.\\n'.format(count)\n",
    "\n",
    "    # for each configuration: construct the according visualization\n",
    "    for config in configuration['visualizations']['free']:\n",
    "        if config['plot'] == 'wordcloud':\n",
    "            ret += free.wordcloud(series, file_prefix=file_prefix, show=show)\n",
    "        elif config['plot'] == 'textlist':\n",
    "            ret += free.textlist(series)\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a free matrix question (list of questions with a list of natural language answers)\n",
    "def visualize_freematrix(data:pd.DataFrame, columns, file_prefix=None, show=False):\n",
    "    ret = \"\"\n",
    "    # for each configuration: construct the according visualization\n",
    "    for config in configuration['visualizations']['free']:\n",
    "        if config['plot'] == 'textlist':\n",
    "            ret += free.multitextlist(data, columns)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Understanding Requirements Engineering Debt\n",
      "## P1 Causes\n",
      "### In your experience, which of the following options qualify as causes of requirements engineering debt?\n",
      "![alt text](./test/figs/auto_gen\\P1_Causes\\9267132_distribution_bar.png \"Title\")\n",
      "![alt text](./test/figs/auto_gen\\P1_Causes\\9267132_vote-count_distribution_hist.png \"Title\")\n",
      "Of those (4) who filled out \"9267132  Other (please specify) string\" the following wordcloud could be built:\n",
      "![alt text](./test/figs/auto_gen\\P1_Causes\\9267132_9267132__Other_(please_specify)_string_wordcloud.png \"Title\")\n",
      "### To what extentÂ do you agree with the statement: \"The overall software process model has an influence on the likelihood of introducing requirements engineering debt.\"\n",
      "This question was answered by 68 participants.\n",
      "![['Fully disagree: 1', 'Rather disagree: 3', 'Neither disagree nor agree: 14', 'Rather agree: 33', 'Fully agree: 17']](./test/figs/auto_gen\\P1_Causes\\9267269_bar_8.png \"Title\")\n",
      "### Please motivate your answer to the question above.\n",
      "This question was answered by 36 participants.\n",
      "The answers result in the following wordcloud:\n",
      "![alt text](./test/figs/auto_gen\\P1_Causes\\9267283_wordcloud.png \"Title\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the markdown report \n",
    "report = '# {}\\n'.format(cbp.get_codebook()['title'])\n",
    "print('# {}'.format(cbp.get_codebook()['title']))\n",
    "for page in [pproc.pages[2]]:\n",
    "    mpage = page_to_markdown(page, directory=figures_save_dir)\n",
    "    print (mpage)\n",
    "    report += mpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Report.md', 'w+') as file:\n",
    "    file.write(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
